{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read success\n",
      "sound shape:  (2048,)\n"
     ]
    }
   ],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "\n",
    "# read file \n",
    "FPB = 2048\n",
    "file_path = \"example.wav\"\n",
    "# 读取本地文件\n",
    "with wave.open(file_path, 'rb') as wf:\n",
    "    signal = wf.readframes(FPB)\n",
    "    sound = np.frombuffer(signal, dtype=np.int16).astype(np.float32) / 32768\n",
    "\n",
    "print(\"sound shape: \", sound.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-2.8061587e-04],\n",
       "        [-1.7931614e-03],\n",
       "        [-2.2212041e-03],\n",
       "        ...,\n",
       "        [-5.8562870e-05],\n",
       "        [-4.4033848e-05],\n",
       "        [-4.7326383e-05]], dtype=float32),\n",
       " 8000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import soundfile as sf\n",
    "import rir_generator as rir\n",
    "import scipy.signal as ss\n",
    "import numpy as np\n",
    "import wave\n",
    "\n",
    "def add_room_reverb(audio_path, save_path, \n",
    "                   room_dim=[5, 4, 6],\n",
    "                   source_pos=[2, 3.5, 2],\n",
    "                   receiver_pos=[2, 1.5, 2],\n",
    "                   rt60=0.4):\n",
    "    \"\"\"\n",
    "    添加基于房间模型的混响效果\n",
    "    \n",
    "    参数:\n",
    "    - audio_path: 输入音频文件路径\n",
    "    - save_path: 输出音频文件路径\n",
    "    - room_dim: 房间尺寸 [x y z] (米)\n",
    "    - source_pos: 声源位置 [x y z] (米)\n",
    "    - receiver_pos: 接收器位置 [x y z] (米)\n",
    "    - rt60: 混响时间(秒)\n",
    "    \"\"\"\n",
    "    # 使用 wave 读取音频\n",
    "    with wave.open(audio_path, 'rb') as wav:\n",
    "        # 获取音频参数\n",
    "        fs = wav.getframerate()\n",
    "        n_channels = wav.getnchannels()\n",
    "        sampwidth = wav.getsampwidth()\n",
    "        n_frames = wav.getnframes()\n",
    "        \n",
    "        # 读取音频数据并转换为numpy数组\n",
    "        signal = wav.readframes(n_frames)\n",
    "        signal = np.frombuffer(signal, dtype=np.int16)\n",
    "        \n",
    "        # 重塑数组为(n_samples, n_channels)\n",
    "        signal = signal.reshape(-1, n_channels)\n",
    "        # 转换为float类型进行处理\n",
    "        signal = signal.astype(np.float32) / 32768.0\n",
    "\n",
    "    # 生成房间冲击响应\n",
    "    h = rir.generate(\n",
    "        c=340,                      # 声速 (m/s)\n",
    "        fs=fs,                      # 采样率\n",
    "        r=[receiver_pos],           # 接收器位置\n",
    "        s=source_pos,               # 声源位置\n",
    "        L=room_dim,                 # 房间尺寸\n",
    "        reverberation_time=rt60,    # 混响时间\n",
    "        nsample=4096                # 输出样本数\n",
    "    )\n",
    "    \n",
    "    # 确保h形状正确 (nsample, 1)\n",
    "    h = h.reshape(-1, 1)\n",
    "    \n",
    "    # 对每个声道进行卷积\n",
    "    reverbed = np.zeros_like(signal)\n",
    "    for i in range(signal.shape[1]):\n",
    "        reverbed[:, i] = ss.convolve(signal[:, i], h[:, 0], mode='same')\n",
    "    \n",
    "    # 归一化输出\n",
    "    reverbed = reverbed / np.max(np.abs(reverbed))\n",
    "    \n",
    "    # 保存处理后的音频\n",
    "    sf.write(save_path, reverbed, fs)\n",
    "    \n",
    "    return reverbed, fs\n",
    "\n",
    "\n",
    "add_room_reverb(\"example.wav\", \"example_reverbed.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "\n",
    "def add_room_reverb(input_signal, fs,\n",
    "                   room_dim=[5.0, 4.0, 6.0],\n",
    "                   source_pos=[2.0, 3.5, 2.0],\n",
    "                   receiver_pos=[2.0, 1.5, 2.0],\n",
    "                   rt60=0.4):\n",
    "    h = rir.generate(\n",
    "        c=340,\n",
    "        fs=fs,\n",
    "        r=[receiver_pos],\n",
    "        s=source_pos,\n",
    "        L=room_dim,\n",
    "        reverberation_time=rt60,\n",
    "        nsample=4096\n",
    "    )\n",
    "    h = h.reshape(-1, 1)\n",
    "    reverbed = ss.convolve(input_signal, h[:, 0], mode='same')\n",
    "    max_val = np.max(np.abs(reverbed))\n",
    "    if max_val > 1e-6:\n",
    "        reverbed = reverbed / max_val\n",
    "    else:\n",
    "        reverbed = np.zeros_like(reverbed)\n",
    "    return reverbed\n",
    "\n",
    "\n",
    "audio_path = \"example.wav\"\n",
    "with wave.open(audio_path, 'rb') as wav:\n",
    "    # 获取音频参数\n",
    "    fs = wav.getframerate()\n",
    "    n_channels = wav.getnchannels()\n",
    "    sampwidth = wav.getsampwidth()\n",
    "    n_frames = wav.getnframes()\n",
    "    \n",
    "    # 读取音频数据并转换为numpy数组\n",
    "    signal = wav.readframes(n_frames)\n",
    "    signal = np.frombuffer(signal, dtype=np.int16)\n",
    "    \n",
    "    # 重塑数组为(n_samples, n_channels)\n",
    "    signal = signal.reshape(-1, n_channels)\n",
    "    # 转换为float类型进行处理\n",
    "    signal = signal.astype(np.float32) / 32768.0\n",
    "\n",
    "reverbed = add_room_reverb(signal[:, 0], fs)\n",
    "\n",
    "\n",
    "# 准备音频播放参数\n",
    "CHANNELS = 1\n",
    "RATE = fs\n",
    "WIDTH = 2  # 16位采样\n",
    "FPB = 1024  # 每个缓冲区的帧数\n",
    "# 将float32转换回int16进行播放\n",
    "audio_data = (reverbed * 32767).astype(np.int16)\n",
    "\n",
    "# 初始化PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# 打开音频流\n",
    "stream = p.open(\n",
    "    format=p.get_format_from_width(WIDTH),\n",
    "    channels=CHANNELS,\n",
    "    rate=RATE,\n",
    "    input=False,\n",
    "    output=True,\n",
    "    frames_per_buffer=FPB\n",
    ")\n",
    "\n",
    "# 播放音频\n",
    "try:\n",
    "    stream.write(audio_data.tobytes())\n",
    "finally:\n",
    "    # 关闭音频流\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 8000)\n",
      "8000\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 8000)\n",
      "8000\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 8000)\n",
      "8000\n",
      "<class 'numpy.ndarray'>\n",
      "(1, 3200)\n",
      "8000\n"
     ]
    }
   ],
   "source": [
    "from pedalboard import Pedalboard, Reverb\n",
    "from pedalboard.io import AudioFile\n",
    "\n",
    "# Make a Pedalboard object, containing multiple audio plugins:\n",
    "board = Pedalboard([Reverb(room_size=0.25)])\n",
    "\n",
    "# Open an audio file for reading, just like a regular file:\n",
    "with AudioFile('example.wav') as f:\n",
    "\n",
    "  # Open an audio file to write to:\n",
    "  with AudioFile('output.wav', 'w', f.samplerate, f.num_channels) as o:\n",
    "\n",
    "    # Read one second of audio at a time, until the file is empty:\n",
    "    while f.tell() < f.frames:\n",
    "      chunk = f.read(f.samplerate)\n",
    "      print(type(chunk))\n",
    "      print(chunk.shape)\n",
    "      print(f.samplerate)\n",
    "      # Run the audio through our pedalboard:\n",
    "      effected = board(chunk, f.samplerate, reset=False)\n",
    "\n",
    "      # Write the output to our output file:\n",
    "      o.write(effected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device 0: LG HDR 4K, Input channels: 0\n",
      "Device 1: HK SoundSticks 4, Input channels: 0\n",
      "Device 2: Grace的大耳朵👂 - Find My, Input channels: 1\n",
      "Device 3: Grace的大耳朵👂 - Find My, Input channels: 0\n",
      "Device 4: BlackHole 2ch, Input channels: 2\n",
      "Device 5: MacBook Pro麦克风, Input channels: 1\n",
      "Device 6: MacBook Pro扬声器, Input channels: 0\n",
      "Device 7: “Angelo”的麦克风, Input channels: 1\n",
      "Device 8: quickTime input, Input channels: 2\n",
      "Device 9: LG+MAC, Input channels: 0\n",
      "Device 10: Screen Recording Audio, Input channels: 0\n",
      "未找到麦克风设备\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "\n",
    "p = pyaudio.PyAudio()\n",
    "\n",
    "# 找到麦克风设备索引\n",
    "# 您需要根据设备名称判断，下面的例子只展示基本方法\n",
    "device_index = None\n",
    "for i in range(p.get_device_count()):\n",
    "    info = p.get_device_info_by_index(i)\n",
    "    print(f\"Device {i}: {info.get('name')}, Input channels: {info.get('maxInputChannels')}\")\n",
    "    # 假设找到名称中包含\"mic\"的设备作为麦克风\n",
    "    if \"mic\" in info.get('name').lower():\n",
    "        device_index = i\n",
    "\n",
    "if device_index is None:\n",
    "    print(\"未找到麦克风设备\")\n",
    "else:\n",
    "    test_rates = [8000, 16000, 22050, 32000, 44100, 48000, 96000]\n",
    "    \n",
    "    for rate in test_rates:\n",
    "        try:\n",
    "            if p.is_format_supported(rate,\n",
    "                                     input_device=device_index,\n",
    "                                     input_channels=1,\n",
    "                                     input_format=pyaudio.paFloat32):\n",
    "                print(f\"支持采样率: {rate} Hz\")\n",
    "            else:\n",
    "                print(f\"不支持采样率: {rate} Hz\")\n",
    "        except ValueError:\n",
    "            print(f\"不支持采样率: {rate} Hz\")\n",
    "\n",
    "p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  353],\n",
       "       [  510],\n",
       "       [  494],\n",
       "       ...,\n",
       "       [-1549],\n",
       "       [-1559],\n",
       "       [-1827]], dtype=int16)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def add_reverb_pedalboard(audio_path, save_path, room_size=0.8, wet_level=0.8):\n",
    "    \"\"\"使用 Pedalboard 添加混响效果\n",
    "    Args:\n",
    "        audio_path (str): 输入音频路径\n",
    "        save_path (str): 输出音频路径\n",
    "        room_size (float): 房间大小 (0-1)\n",
    "        wet_level (float): 湿信号比例 (0-1)\n",
    "    \"\"\"\n",
    "    from pedalboard import Pedalboard, Reverb\n",
    "    import wave\n",
    "    import numpy as np\n",
    "\n",
    "    # 读取wave文件\n",
    "    with wave.open(audio_path, 'rb') as wf:\n",
    "        # 获取音频参数\n",
    "        channels = wf.getnchannels()\n",
    "        sample_width = wf.getsampwidth()\n",
    "        sample_rate = wf.getframerate()\n",
    "        n_frames = wf.getnframes()\n",
    "        \n",
    "        # 读取音频数据\n",
    "        audio_data = wf.readframes(n_frames)\n",
    "        audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
    "        \n",
    "        # 转换为float32格式 (-1 到 1)\n",
    "        audio_float = audio_array.astype(np.float32) / 32768.0\n",
    "        \n",
    "        # 重塑数组以匹配声道\n",
    "        if channels == 2:\n",
    "            audio_float = audio_float.reshape(-1, 2)\n",
    "        else:\n",
    "            audio_float = audio_float.reshape(-1, 1)\n",
    "\n",
    "    # 创建效果器\n",
    "    board = Pedalboard([Reverb(\n",
    "        room_size=room_size,\n",
    "        wet_level=wet_level\n",
    "    )])\n",
    "\n",
    "    # 应用效果\n",
    "    effected = board(audio_float, sample_rate)\n",
    "\n",
    "    # 转换回int16格式\n",
    "    audio_int = (effected * 32768).astype(np.int16)\n",
    "\n",
    "    # 保存处理后的音频\n",
    "    with wave.open(save_path, 'wb') as wf:\n",
    "        wf.setnchannels(channels)\n",
    "        wf.setsampwidth(sample_width)\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(audio_int.tobytes())\n",
    "\n",
    "    return audio_int\n",
    "\n",
    "\n",
    "add_reverb_pedalboard(\"example.wav\", \"2222_reverbed.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import numpy as np\n",
    "from pedalboard import Pedalboard, Reverb\n",
    "\n",
    "def process_audio_by_frames(input_path, output_path, frame_size=2048*100, room_size=0.8, wet_level=0.8):\n",
    "    # 创建效果器\n",
    "    board = Pedalboard([Reverb(room_size=room_size, wet_level=wet_level)])\n",
    "    \n",
    "    with wave.open(input_path, 'rb') as wf_in:\n",
    "        # 获取音频参数\n",
    "        channels = wf_in.getnchannels()\n",
    "        sample_width = wf_in.getsampwidth()\n",
    "        sample_rate = wf_in.getframerate()\n",
    "        \n",
    "        with wave.open(output_path, 'wb') as wf_out:\n",
    "            # 设置输出文件参数\n",
    "            wf_out.setnchannels(channels)\n",
    "            wf_out.setsampwidth(sample_width)\n",
    "            wf_out.setframerate(sample_rate)\n",
    "            \n",
    "            # 逐帧处理\n",
    "            while True:\n",
    "                # 读取一帧数据\n",
    "                audio_data = wf_in.readframes(frame_size)\n",
    "                if not audio_data:\n",
    "                    break\n",
    "                    \n",
    "                # 转换为numpy数组\n",
    "                audio_array = np.frombuffer(audio_data, dtype=np.int16)\n",
    "                \n",
    "                # 转换为float32\n",
    "                audio_float = audio_array.astype(np.float32) / 32768.0\n",
    "                \n",
    "                # 重塑数组\n",
    "                if channels == 2:\n",
    "                    audio_float = audio_float.reshape(-1, 2)\n",
    "                else:\n",
    "                    audio_float = audio_float.reshape(-1, 1)\n",
    "                \n",
    "                # 应用效果\n",
    "                effected = board(audio_float, sample_rate)\n",
    "                \n",
    "                # 转回int16\n",
    "                audio_int = (effected * 32768).astype(np.int16)\n",
    "                \n",
    "                # 写入输出文件\n",
    "                wf_out.writeframes(audio_int.tobytes())\n",
    "\n",
    "# 使用示例\n",
    "process_audio_by_frames('222.wav', 'output_222.wav', frame_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pedalboard import Pedalboard, Reverb\n",
    "from pedalboard.io import AudioFile\n",
    "\n",
    "# Make a Pedalboard object, containing multiple audio plugins:\n",
    "board = Pedalboard([Reverb(room_size=0.25)])\n",
    "\n",
    "# Open an audio file for reading, just like a regular file:\n",
    "with AudioFile('222.wav') as f:\n",
    "\n",
    "  # Open an audio file to write to:\n",
    "  with AudioFile('output.wav', 'w', f.samplerate, f.num_channels) as o:\n",
    "\n",
    "    # Read one second of audio at a time, until the file is empty:\n",
    "    while f.tell() < f.frames:\n",
    "      chunk = f.read(f.samplerate)\n",
    "\n",
    "      # Run the audio through our pedalboard:\n",
    "      effected = board(chunk, f.samplerate, reset=False)\n",
    "\n",
    "      # Write the output to our output file:\n",
    "      o.write(effected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理...\n",
      "停止处理\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import numpy as np\n",
    "from pedalboard import Pedalboard, Reverb\n",
    "\n",
    "class RealtimeReverb:\n",
    "    def __init__(self):\n",
    "        # 音频参数\n",
    "        self.CHUNK = 1024\n",
    "        self.FORMAT = pyaudio.paFloat32\n",
    "        self.CHANNELS = 1\n",
    "        self.RATE = 44100\n",
    "        \n",
    "        # 创建效果器\n",
    "        self.board = Pedalboard([\n",
    "            Reverb(\n",
    "                room_size=0.8,\n",
    "                wet_level=0.7,\n",
    "                damping=0.5,\n",
    "                width=1.0\n",
    "            )\n",
    "        ])\n",
    "        \n",
    "        # 初始化PyAudio\n",
    "        self.p = pyaudio.PyAudio()\n",
    "        self.stream = self.p.open(\n",
    "            format=self.FORMAT,\n",
    "            channels=self.CHANNELS,\n",
    "            rate=self.RATE,\n",
    "            input=True,\n",
    "            output=True,\n",
    "            frames_per_buffer=self.CHUNK,\n",
    "            stream_callback=self.audio_callback\n",
    "        )\n",
    "        \n",
    "    def audio_callback(self, in_data, frame_count, time_info, status):\n",
    "        try:\n",
    "            # 转换输入数据\n",
    "            audio_data = np.frombuffer(in_data, dtype=np.float32)\n",
    "            \n",
    "            # 重塑数组\n",
    "            if audio_data.ndim == 1:\n",
    "                audio_data = audio_data.reshape(-1, 1)\n",
    "            \n",
    "            # 应用效果\n",
    "            processed = self.board(audio_data, self.RATE)\n",
    "            \n",
    "            return (processed.tobytes(), pyaudio.paContinue)\n",
    "        except Exception as e:\n",
    "            print(f\"处理错误: {str(e)}\")\n",
    "            return (in_data, pyaudio.paContinue)\n",
    "            \n",
    "    def start(self):\n",
    "        self.stream.start_stream()\n",
    "        print(\"开始处理...\")\n",
    "        try:\n",
    "            while self.stream.is_active():\n",
    "                import time\n",
    "                time.sleep(0.1)\n",
    "        except KeyboardInterrupt:\n",
    "            print(\"停止处理\")\n",
    "        finally:\n",
    "            self.stop()\n",
    "            \n",
    "    def stop(self):\n",
    "        self.stream.stop_stream()\n",
    "        self.stream.close()\n",
    "        self.p.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    processor = RealtimeReverb()\n",
    "    try:\n",
    "        processor.start()\n",
    "    except Exception as e:\n",
    "        print(f\"运行错误: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 开始录音和实时处理. 按 Ctrl+C 停止.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import wave\n",
    "import numpy as np\n",
    "from pedalboard import Pedalboard, Reverb\n",
    "from pedalboard.io import AudioFile\n",
    "import pyaudio\n",
    "\n",
    "board = Pedalboard([Reverb(room_size=0.8, wet_level=0.7, damping=0.5, width=1.0)])\n",
    "\n",
    "def process_audio_chunk(in_data, frame_count, time_info, status):\n",
    "    \"\"\"使用 AudioFile 处理音频数据\"\"\"\n",
    "    audio_data = np.frombuffer(in_data, dtype=np.float32)\n",
    "\n",
    "    # 创建临时文件存储音频块\n",
    "    with tempfile.NamedTemporaryFile(suffix='.wav') as temp_in, \\\n",
    "            tempfile.NamedTemporaryFile(suffix='.wav') as temp_out:\n",
    "        \n",
    "        # 保存输入数据到临时文件\n",
    "        with wave.open(temp_in.name, 'wb') as wf:\n",
    "            wf.setnchannels(1)\n",
    "            wf.setsampwidth(4)  # float32\n",
    "            wf.setframerate(44100)\n",
    "            wf.writeframes(audio_data)\n",
    "        \n",
    "        # 使用 AudioFile 处理\n",
    "        with AudioFile(temp_in.name) as f:\n",
    "            with AudioFile(temp_out.name, 'w', f.samplerate, f.num_channels) as o:\n",
    "                while f.tell() < f.frames:\n",
    "                    chunk = f.read(f.samplerate)\n",
    "                    # Run the audio through our pedalboard:\n",
    "                    effected = board(chunk, f.samplerate, reset=False)\n",
    "                    # Write the output to our output file:\n",
    "                    o.write(effected)\n",
    "        \n",
    "        # 读取处理后的数据\n",
    "        with wave.open(temp_out.name, 'rb') as wf:\n",
    "            processed_data = wf.readframes(wf.getnframes())\n",
    "            \n",
    "        return (processed_data, pyaudio.paContinue)\n",
    "    \n",
    "def main():\n",
    "    p = pyaudio.PyAudio()\n",
    "    \n",
    "    stream = p.open(\n",
    "        format=pyaudio.paFloat32,\n",
    "        channels=1,\n",
    "        rate=44100,\n",
    "        input=True,\n",
    "        output=True,\n",
    "        frames_per_buffer=1024,\n",
    "        stream_callback=process_audio_chunk\n",
    "    )\n",
    "    \n",
    "    print(\"* 开始录音和实时处理. 按 Ctrl+C 停止.\")\n",
    "    \n",
    "    try:\n",
    "        while stream.is_active():\n",
    "            stream.start_stream()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"* 停止录音\")\n",
    "    finally:\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
